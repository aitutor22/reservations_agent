# Ramen Restaurant Voice Agent

> AI-powered voice agent for ramen restaurant reservations using OpenAI Realtime API

## Architecture
- Frontend: React + TypeScript with WebSocket for real-time audio
- Backend: FastAPI with OpenAI Agents SDK
- Voice Processing: OpenAI Realtime API (speech-to-speech)
- Integration: Future POS system for reservation management

## Key Components
- Main greeting agent routes to specialized agents
- General info agent handles hours, location, daily specials, ramen varieties  
- Reservation agent manages bookings with tool calling
- WebSocket maintains persistent audio connection

## API Endpoints
- POST /api/reservations - Create new reservation
- PUT /api/reservations/modify - Modify existing booking
- DELETE /api/reservations/cancel - Cancel reservation
- GET /api/session/health - WebSocket health check
- WS /ws/audio - WebSocket endpoint for audio streaming

## Data Models
```typescript
interface Reservation {
  id: string;
  date: string;
  time: string;
  partySize: number;
  name: string;
  phone: string;
  email?: string;
  confirmationNumber: string;
  specialRequests?: string;
  seatingPreference?: 'counter' | 'table' | 'booth' | 'no-preference';
  dietaryRestrictions?: string[];
  status: 'confirmed' | 'cancelled' | 'modified';
}

interface AudioChunk {
  data: ArrayBuffer;
  timestamp: number;
  role: 'user' | 'agent';
}
```

## Conversation Flow
1. Greeting: "Welcome to [Ramen Restaurant Name], how can I help you?"
2. Intent Detection: Routes to appropriate agent
3. Information Gathering: Collects necessary details (including seating preferences for counter, booth, etc.)
4. Action Execution: Creates/modifies/cancels reservation
5. Confirmation: Provides confirmation number and summary

## Development Patterns
- Component-based React architecture
- WebSocket connection with auto-reconnect
- Error boundaries for graceful failure handling
- Type-safe API calls with TypeScript
- Async/await pattern for all API operations

## Voice Personality System

### Overview
The restaurant uses a modular voice personality system that ensures consistent character across all agents while allowing role-specific behaviors. The personality is defined in `backend/realtime_agents/voice_personality.py`.

### Personality Structure
```python
# Base personality (shared by all agents)
BASE_PERSONALITY = """
- Identity: Refined Japanese restaurant receptionist
- Accent: Singaporean (gentle and clear)
- Demeanor: Professional, warm, calm, composed
- Cultural: Embodies omotenashi (Japanese hospitality)
"""

# Role-specific additions
MAIN_AGENT_ROLE = """Greeting and information specialist"""
RESERVATION_AGENT_ROLE = """Efficient reservation specialist"""
```

### Voice Configuration
- **Voice**: "verse" - Warm, friendly, clear articulation
- **Temperature**: 0.8 - Natural variation without losing consistency
- **VAD Settings**: Optimized for phone conversations
  - Threshold: 0.5 (balanced sensitivity)
  - Silence duration: 500ms (natural pause detection)
  - Prefix padding: 300ms (captures complete utterances)

### Key Personality Traits
- **Conversational Style**: Concise, natural, moderate-slow pacing
- **Speech Patterns**: Clean articulation, no filler words
- **Formality**: Professional casual with respectful address
- **Enthusiasm**: Moderate, welcoming without overwhelming
- **Cultural Elements**: Japanese hospitality, anticipates needs

### Implementation Pattern
```python
from voice_personality import get_agent_instructions

agent = RealtimeAgent(
    name="SakuraRamenAssistant",
    instructions=get_agent_instructions("main"),
    tools=[...]
)
```

### Benefits
- Consistent personality across handoffs
- Easy to maintain and update
- Role-specific customization
- Cultural authenticity
- Natural voice interactions

## RealtimeAgent API Integration Patterns

### Function Tools and REST APIs
RealtimeAgent function tools make REST API calls to backend services:
- Tools use `httpx.AsyncClient` for non-blocking HTTP calls (NOT requests)
- Connection pooling with singleton client pattern for efficiency
- Internal networking preferred (localhost in dev, service names in production)
- Proper error handling with user-friendly messages

### Why httpx Over requests
- **Async Support**: Native async/await prevents event loop blocking
- **Voice Performance**: Concurrent API calls reduce latency
- **Real-time Audio**: Non-blocking I/O maintains smooth audio streaming
- **Connection Pooling**: Reuses connections for better performance

### Typical Latency Breakdown
```
Speech-to-text: ~200-300ms
LLM processing: ~300-500ms  
API call:       ~50-200ms (only 5-12% of total!)
LLM response:   ~200-300ms
Text-to-speech: ~200-300ms
Total:          ~1000-1600ms
```

### Network Architecture
- **Development**: `http://localhost:8000`
- **Docker**: `http://api:8000` (container name)
- **Kubernetes**: `http://reservation-api:8000` (service name)
- **Cloud VPC**: `http://10.0.1.20:8000` (private IP)
- **External**: Only for third-party services (Stripe, Twilio, etc.)

### Tool Implementation Example
```python
@function_tool
async def make_reservation(...) -> str:
    client = await get_api_client()  # Singleton httpx client
    try:
        response = await client.post("/api/reservations", json=data)
        if response.status_code == 200:
            return f"✅ Confirmed! #{response.json()['id']}"
        else:
            return "❌ Unable to book. Please try again."
    except httpx.TimeoutException:
        return "❌ System is slow. Please try again."
```

For detailed documentation, see:
- `docs/backend/realtime_agent_api_integration.md` - Complete API integration guide
- `docs/backend/networking_architecture.md` - Network strategies from dev to production